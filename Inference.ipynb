{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecasting without Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "1. [Setup](#toc1_)    \n",
    "2. [Model](#toc2_)    \n",
    "2.1. [1 Hidden layer](#toc2_1_)    \n",
    "2.2. [Multiple Hidden layers](#toc2_2_)    \n",
    "3. [Functions](#toc3_)    \n",
    "3.1. [Prepare Data](#toc3_1_)    \n",
    "3.2. [Train & Evaluate](#toc3_2_)    \n",
    "3.3. [Load Data & Predict](#toc3_3_)    \n",
    "3.4. [Predict](#toc3_4_)    \n",
    "4. [Hyperparameter tuning](#toc4_)    \n",
    "5. [User Call](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from pprint import pprint\n",
    "from prettytable import PrettyTable\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_layers, output_size):\n",
    "        super(DynamicLSTM, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.LSTM(input_size, hidden_sizes[0], num_layers=1, batch_first=True))\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.hidden_layers.append(nn.LSTM(hidden_sizes[i-1], hidden_sizes[i], num_layers=1, batch_first=True))\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x, _ = layer(x)\n",
    "            # x, _ = layer(x.to(device))  # Move input to GPU\n",
    "        x = self.output_layer(x[:, -1, :])  # Take the output from the last time step\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[Functions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[Prepare Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data_multivariate(df, choosen_stock, startdate, enddate, features, look_back, predict_type='year'):\n",
    "    # Choose specific stock\n",
    "    data = df[df[\"Stock\"] == choosen_stock]\n",
    "\n",
    "    # Test split\n",
    "    if predict_type=='year':\n",
    "        test_data = data[data[\"Date\"].dt.year == 2023]\n",
    "    elif predict_type=='month':\n",
    "        test_data = data[(data[\"Date\"].dt.year == 2023) & (data[\"Date\"].dt.month.isin([1]))]\n",
    "    elif predict_type=='days':\n",
    "        test_data = data[data[\"Date\"].dt.year == 2023][0:20] \n",
    "    elif predict_type=='forecast':\n",
    "        test_data = data[(data[\"Date\"] >= dt.datetime(2023, 10, 12)) & (data[\"Date\"] <= enddate)]\n",
    "\n",
    "    # Train split\n",
    "    if predict_type=='forecast':\n",
    "        train_data = data[(data[\"Date\"] >= startdate) & (data[\"Date\"] <= dt.datetime(2023, 10, 11))]\n",
    "    else:\n",
    "        train_data = data[(data[\"Date\"] >= startdate) & (data[\"Date\"] <= dt.datetime(2022, 12, 31))]\n",
    "    \n",
    "    # Feature selection and engineering\n",
    "    train_data = train_data[features + [\"Date\"]].values\n",
    "    test_data = test_data[features + [\"Date\"]].values\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data[:, :-1] = scaler.fit_transform(train_data[:, :-1])\n",
    "    test_data[:, :-1] = scaler.transform(test_data[:, :-1])\n",
    "    \n",
    "    # Create sequences for LSTM input\n",
    "    def create_sequences(dataset, look_back):\n",
    "        X, Y, dates = [], [], []\n",
    "        for i in range(len(dataset) - look_back):\n",
    "            X.append(dataset[i:(i + look_back), :-1])\n",
    "            Y.append(dataset[i + look_back, 0])\n",
    "            dates.append(dataset[i + look_back, -1])  # Assuming the last column is 'Date'\n",
    "        return np.array(X), np.array(Y), np.array(dates)\n",
    "    train_X, train_Y, train_dates = create_sequences(train_data, look_back)\n",
    "    test_X, test_Y, test_dates = create_sequences(test_data, look_back)\n",
    "    \n",
    "    # Convert data to PyTorch tensors and move to GPU\n",
    "    train_X = torch.Tensor(train_X.astype(np.float32))#.to(device)\n",
    "    train_Y = torch.Tensor(train_Y)#.to(device)\n",
    "    test_X = torch.Tensor(test_X.astype(np.float32))#.to(device)\n",
    "    test_Y = torch.Tensor(test_Y)#.to(device)\n",
    "    \n",
    "    return train_X, train_Y, train_dates, test_X, test_Y, test_dates, scaler, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[Train & Evaluate](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_lstm_multivariate(input_size, hidden_sizes, num_layers, output_size, learning_rate, num_epochs, train_X, train_Y, test_X, test_Y, scaler, test_data, test_dates, visualize=True):\n",
    "    # Initialize the model\n",
    "    # model = MultivariateLSTMModel(input_size, hidden_sizes, num_layers, output_size)\n",
    "    # model = DynamicLSTM(input_size, hidden_sizes, num_layers, output_size)\n",
    "    model = DynamicLSTM(input_size, hidden_sizes, num_layers, output_size)# .to(device)\n",
    "    # print(model)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Move data to GPU\n",
    "    # train_X, train_Y, test_X, test_Y = train_X.to(device), train_Y.to(device), test_X.to(device), test_Y.to(device)\n",
    "    \n",
    "    \n",
    "    # Training the model\n",
    "    train_losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(train_X)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs.view(-1), train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # Calculate predictions\n",
    "    model.eval()\n",
    "    train_predict = model(train_X).view(-1).cpu().detach().numpy()\n",
    "    test_predict = model(test_X).view(-1).cpu().detach().numpy()\n",
    "    \n",
    "    # Compute RMSE & MAPE\n",
    "    # train_rmse = mean_squared_error(train_Y.cpu(), train_predict, squared=False)\n",
    "    # test_rmse = mean_squared_error(test_Y.cpu(), test_predict, squared=False)\n",
    "    # train_mape = mean_absolute_percentage_error(train_Y.cpu(), train_predict)\n",
    "    # test_mape = mean_absolute_percentage_error(test_Y.cpu(), test_predict)\n",
    "    train_rmse = mean_squared_error(train_Y, train_predict, squared=False)\n",
    "    test_rmse = mean_squared_error(test_Y, test_predict, squared=False)\n",
    "    train_mape = mean_absolute_percentage_error(train_Y, train_predict)\n",
    "    test_mape = mean_absolute_percentage_error(test_Y, test_predict)\n",
    "    \n",
    "    # Inverse Scaling\n",
    "    # --> 1.test_predict\n",
    "    test_data1 = test_data[:, 1:-1]\n",
    "    # Ensure the second array has the same number of rows as the first array\n",
    "    test_data1 = test_data1[:test_predict.reshape(-1, 1).shape[0], :]\n",
    "    # Append the arrays\n",
    "    test_data1 = np.hstack((test_predict.reshape(-1, 1), test_data1)) \n",
    "    test_predict_inverse = scaler.inverse_transform(test_data1)[:,0]\n",
    "    \n",
    "    # --> 2.test_Y\n",
    "    test_data2 = test_data[:, :-1]\n",
    "    test_data2 = test_data2[:test_predict.reshape(-1, 1).shape[0], :]\n",
    "    test_Y_inverse = scaler.inverse_transform(test_data2)[:,0]\n",
    "    \n",
    "    # Visualize test and predictions\n",
    "    if visualize == True:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_dates, test_Y_inverse, label='True', linewidth=2)\n",
    "        plt.plot(test_dates, test_predict_inverse, label='Predicted', linewidth=2)\n",
    "        plt.title(\"Test vs. Predicted Prices\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return model, loss, train_rmse, test_rmse, train_mape, test_mape, test_Y_inverse, test_predict_inverse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[Load Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(choosen_stock, predict_type):    \n",
    "    yf.pdr_override() # Override pandas datareader with yfinance\n",
    "    y_symbols = [choosen_stock]\n",
    "\n",
    "    # Train split\n",
    "    if predict_type=='forecast':\n",
    "        # State the dates\n",
    "        startdate = dt.datetime(2018, 1, 1) # start date\n",
    "        enddate = dt.datetime(2023, 12, 12) # end date\n",
    "\n",
    "        # Retrieve historical stock price data for the specified symbols and date range\n",
    "        df = yf.download(y_symbols, start=startdate, end=enddate) \n",
    "        df = df.reset_index() # Reset the index to make 'Date' a regular column\n",
    "        df['Stock'] = choosen_stock # add 'Stock' column\n",
    "        df = df[['Date', 'Stock', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']] # Reorder the columns\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # add new row\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-12T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-13T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-14T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-15T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-16T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        \n",
    "        return df, startdate, dt.datetime(2023, 12, 18) \n",
    "    \n",
    "    else:\n",
    "        startdate = dt.datetime(2015, 1, 1) # start date\n",
    "        enddate = dt.datetime(2023, 11, 1) # end date\n",
    "        \n",
    "        # Retrieve historical stock price data for the specified symbols and date range\n",
    "        df = yf.download(y_symbols, start=startdate, end=enddate) \n",
    "        df = df.reset_index() # Reset the index to make 'Date' a regular column\n",
    "        df['Stock'] = choosen_stock # add 'Stock' column\n",
    "        df = df[['Date', 'Stock', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']] # Reorder the columns\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "  \n",
    "        return df, startdate, enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='toc3_4_'></a>[Predict](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone prediction\n",
    "def predict(choosen_stock):\n",
    "    # Load the data\n",
    "    data, startdate, enddate = load_data(choosen_stock)\n",
    "\n",
    "    # Append the last row to the DataFrame\n",
    "    new_row = [{'Date':pd.to_datetime('2023-12-01T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "    data = pd.concat([data, pd.DataFrame(new_row)], ignore_index=True)\n",
    "\n",
    "    # 1. Hyperparameters\n",
    "    look_back = 5 # No. of Lags to consider\n",
    "    predict_type = 'Predict' # Predict type ['Year', 'Month', 'Days','Predict']\n",
    "    features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    predict_type = 'Predict'                            # Predict type ['Year', 'Month', 'Days','Predict']\n",
    "    hidden_sizes = [64, 64]                   # Adjust the hidden_size values as needed\n",
    "    num_layers = 2                       # [1, 2, 3]\n",
    "    learning_rate = 0.001         # [0.005, 0.01, 0.02]  \n",
    "    num_epochs = 100                                    # [50, 100, 200] \n",
    "\n",
    "    # Prepare the data\n",
    "    train_X, train_Y, train_dates, test_X, test_Y, test_dates, scaler, test_data = prepare_data_multivariate(data, choosen_stock, startdate, enddate, features=features, look_back=look_back, predict_type=predict_type )\n",
    "\n",
    "    # 2. Hyperparameters\n",
    "    input_size = 5  # Number of input features (High, Low, Open, Close, Volume)\n",
    "    output_size = 1  # Number of output features (Close price)\n",
    "    num_epochs = 100\n",
    "\n",
    "    # Create the model\n",
    "    model, loss, train_rmse, test_rmse, train_mape, test_mape, test_Y_inverse, test_predict_inverse  = train_evaluate_lstm_multivariate(input_size, hidden_sizes, num_layers, output_size, learning_rate, num_epochs, train_X, train_Y, test_X, test_Y, scaler, test_data, visualize=False)\n",
    "    \n",
    "    # Formatting the prices to a desired decimal form\n",
    "    formatted_test_Y = [\"{:.4f}\".format(price) for price in test_Y_inverse.flatten()]\n",
    "    formatted_test_predict = [\"{:.4f}\".format(price) for price in test_predict_inverse.flatten()]\n",
    "    formatted_dates = [test_dates.strftime('%Y-%m-%d') for test_dates in test_dates]\n",
    "\n",
    "    return formatted_test_Y, formatted_test_predict, formatted_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[Hyperparameter tuning](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOOG\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "AAPL\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "MSFT\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "META\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "AMZN\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "NFLX\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "TSLA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "NVDA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "GME\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Top Performing Models:\n",
      "+--------+-------+-----------+---------------+------------+-------------+------------+-------------+-----------+-----------+\n",
      "| Ticker | Model | Look Back | Learning Rate | Input Size | Hidden Size | Num Layers | Output Size | Test RMSE | Test MAPE |\n",
      "+--------+-------+-----------+---------------+------------+-------------+------------+-------------+-----------+-----------+\n",
      "|  GOOG  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.2583  |   0.1804  |\n",
      "|  AAPL  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.2309  |   0.3126  |\n",
      "|  MSFT  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.2519  |   0.2608  |\n",
      "|  META  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.2105  |   0.2165  |\n",
      "|  AMZN  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.2298  |   0.1762  |\n",
      "|  NFLX  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.1706  |   0.1917  |\n",
      "|  TSLA  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.1142  |   1.0167  |\n",
      "|  NVDA  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.185   |   0.7304  |\n",
      "|  GME   |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.0309  |   0.815   |\n",
      "+--------+-------+-----------+---------------+------------+-------------+------------+-------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the best models for each ticker\n",
    "all_best_models = {}\n",
    "\n",
    "for ticker in ['GOOG', 'AAPL', 'MSFT', 'META', 'AMZN', 'NFLX', 'TSLA', 'NVDA', 'GME']:\n",
    "    print(\"\\n\" + ticker)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    choosen_stock = ticker                              # ['GOOG', 'MSFT', 'META', 'AMZN', 'NFLX', 'TSLA', 'NVDA']\n",
    "    look_back_values = [5]        \n",
    "    # No. of Lags to consider [3, 5, 10, 20]\n",
    "    predict_type = 'forecast'                            # Predict type ['year', 'month', 'days','predict']\n",
    "    hidden_size_options = [64, 128]                      # Adjust the hidden_size values as needed\n",
    "    num_layers_values = [1,2]                       # [1, 2, 3]\n",
    "    learning_rate_values = [0.001, 0.01, 0.005]         # [0.005, 0.01, 0.02]  \n",
    "    num_epochs = 100                                    # [50, 100, 200] \n",
    "    top_k = 1                                           # Get the top k performing models\n",
    "\n",
    "    # ?\n",
    "    years_to_include = [2015, 2016, 2017, 2018, 2019]\n",
    "    train_days_values = [-1, 60, 100, 365, 365*2]\n",
    "\n",
    "\n",
    "    # Features\n",
    "    features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    input_size = 5  # Number of input features (High, Low, Open, Close, Volume)\n",
    "    output_size = 1  # Number of output features (Close price)\n",
    "\n",
    "\n",
    "    # Load the data\n",
    "    df, startdate, enddate = load_data(choosen_stock, predict_type) \n",
    "\n",
    "    # Store best_models\n",
    "    best_models = []\n",
    "\n",
    "    # Hyperparameter tuning loop\n",
    "\n",
    "    for num_layers in num_layers_values:\n",
    "        hidden_size_values = list(product(hidden_size_options, repeat=num_layers))\n",
    "        # print(hidden_size_values)\n",
    "        for hidden_size in hidden_size_values:\n",
    "            # print(hidden_size)\n",
    "            for look_back in look_back_values:\n",
    "                for learning_rate in learning_rate_values:\n",
    "                    # print(f\"\\nHyperparameters: look_back={look_back}, hidden_size={hidden_size}, num_layers={num_layers}, learning_rate={learning_rate}\")\n",
    "                    # Prepare the data\n",
    "                    train_X, train_Y, train_dates, test_X, test_Y, test_dates, scaler, test_data = prepare_data_multivariate(df, choosen_stock, startdate, enddate, features=features, look_back=look_back, predict_type=predict_type)\n",
    "                    model, loss, train_rmse, test_rmse, train_mape, test_mape, test_Y_inverse, test_predict_inverse = train_evaluate_lstm_multivariate(input_size, hidden_size, num_layers, output_size, learning_rate, num_epochs, train_X, train_Y, test_X, test_Y, scaler, test_data, test_dates, visualize=False)\n",
    "                    best_models.append({\n",
    "                        \"model\" : model,\n",
    "                        \"look_back\" : look_back,\n",
    "                        \"learning_rate\" : learning_rate,\n",
    "                        \"input_size\" : input_size,\n",
    "                        \"hidden_size\" : hidden_size,\n",
    "                        \"num_layers\" : num_layers,\n",
    "                        \"output_size\" : output_size,\n",
    "                        \"test_rmse\": test_rmse,\n",
    "                        \"test_mape\": test_mape,\n",
    "                        \"test_X\": test_X,\n",
    "                        \"test_Y_inverse\":test_Y_inverse,\n",
    "                        \"test_predict_inverse\":test_predict_inverse,\n",
    "                        \"test_dates\":test_dates,\n",
    "                        \"test_data\" : test_data,\n",
    "                    })\n",
    "\n",
    "    # Sort the models by RMSE in ascending order\n",
    "    best_models.sort(key=lambda x: (x[\"test_rmse\"], x[\"test_mape\"]))\n",
    "\n",
    "    # Store the top-k performing models for the current ticker\n",
    "    all_best_models[ticker] = best_models[:top_k]\n",
    "\n",
    "# Save Parameters & Weights\n",
    "for ticker, models in all_best_models.items():\n",
    "    for idx, model_info in enumerate(models, start=1):\n",
    "        # Save parameters for the model reload\n",
    "        params_file_name = \"Saved Params/\" + ticker + \"_params.pkl\"\n",
    "        with open(params_file_name, 'wb') as file:\n",
    "            pickle.dump(model_info, file)\n",
    "        # print(f\"Model Parameters for {ticker} saved to {params_file_name}\")\n",
    "        \n",
    "        # Save the model weights to a pickle file\n",
    "        model_filename = f\"Saved Models/{ticker}_model\"\n",
    "        torch.save(model_info[\"model\"].state_dict(), model_filename)\n",
    "        # print(f\"Model weights for {ticker} saved to {model_filename}\")\n",
    "\n",
    "\n",
    "# Print the best models for each ticker\n",
    "# for ticker, models in all_best_models.items():\n",
    "#     print(f\"\\nTop {top_k} Performing Model for {ticker}:\")\n",
    "#     pprint(models)\n",
    "\n",
    "# Assuming all_best_models is a dictionary with tickers as keys and a list of best models as values\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Ticker\", \"Model\", \"Look Back\", \"Learning Rate\", \"Input Size\", \"Hidden Size\", \"Num Layers\", \"Output Size\", \"Test RMSE\", \"Test MAPE\"]\n",
    "\n",
    "for ticker, models in all_best_models.items():\n",
    "    for idx, model_info in enumerate(models, start=1):\n",
    "        table.add_row([\n",
    "            ticker,\n",
    "            idx,\n",
    "            model_info[\"look_back\"],\n",
    "            model_info[\"learning_rate\"],\n",
    "            model_info[\"input_size\"],\n",
    "            model_info[\"hidden_size\"],\n",
    "            model_info[\"num_layers\"],\n",
    "            model_info[\"output_size\"],\n",
    "            round(model_info[\"test_rmse\"], 4),\n",
    "            round(model_info[\"test_mape\"], 4),\n",
    "        ])\n",
    "\n",
    "# Print the combined table\n",
    "print(\"Top Performing Models:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[Forecast](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOOG\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    136.4     |      138.53      |\n",
      "| 2023-11-30 |    133.92    |      138.24      |\n",
      "| 2023-12-01 |    133.32    |      136.63      |\n",
      "| 2023-12-04 |    130.63    |      135.21      |\n",
      "| 2023-12-05 |    132.39    |      133.41      |\n",
      "| 2023-12-06 |    131.43    |      132.77      |\n",
      "| 2023-12-07 |    138.45    |      132.67      |\n",
      "| 2023-12-08 |    136.64    |      134.19      |\n",
      "| 2023-12-11 |    134.7     |      135.14      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      134.83      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "AAPL\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    189.37    |      188.66      |\n",
      "| 2023-11-30 |    189.95    |      188.57      |\n",
      "| 2023-12-01 |    191.24    |      188.14      |\n",
      "| 2023-12-04 |    189.43    |      188.39      |\n",
      "| 2023-12-05 |    193.42    |      188.03      |\n",
      "| 2023-12-06 |    192.32    |      188.57      |\n",
      "| 2023-12-07 |    194.27    |      189.74      |\n",
      "| 2023-12-08 |    195.71    |      190.5       |\n",
      "| 2023-12-11 |    193.18    |      191.21      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      190.93      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "MSFT\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    378.85    |      365.18      |\n",
      "| 2023-11-30 |    378.91    |      365.93      |\n",
      "| 2023-12-01 |    374.51    |      365.46      |\n",
      "| 2023-12-04 |    369.14    |      364.2       |\n",
      "| 2023-12-05 |    372.52    |      361.03      |\n",
      "| 2023-12-06 |    368.8     |      360.01      |\n",
      "| 2023-12-07 |    370.95    |      359.61      |\n",
      "| 2023-12-08 |    374.23    |      358.65      |\n",
      "| 2023-12-11 |    371.3     |      359.18      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      358.75      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "META\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    332.2     |      338.72      |\n",
      "| 2023-11-30 |    327.15    |      337.81      |\n",
      "| 2023-12-01 |    324.82    |      334.12      |\n",
      "| 2023-12-04 |    320.02    |      330.62      |\n",
      "| 2023-12-05 |    318.29    |      325.74      |\n",
      "| 2023-12-06 |    317.45    |      323.18      |\n",
      "| 2023-12-07 |    326.59    |      322.1       |\n",
      "| 2023-12-08 |    332.75    |      322.86      |\n",
      "| 2023-12-11 |    325.28    |      325.69      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      326.27      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "AMZN\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    146.32    |      147.32      |\n",
      "| 2023-11-30 |    146.09    |      147.72      |\n",
      "| 2023-12-01 |    147.03    |      147.04      |\n",
      "| 2023-12-04 |    144.84    |      147.12      |\n",
      "| 2023-12-05 |    146.88    |      146.23      |\n",
      "| 2023-12-06 |    144.52    |      146.23      |\n",
      "| 2023-12-07 |    146.88    |      146.36      |\n",
      "| 2023-12-08 |    147.42    |      146.7       |\n",
      "| 2023-12-11 |    145.89    |      146.91      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      146.57      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "NFLX\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    477.19    |      479.71      |\n",
      "| 2023-11-30 |    473.97    |      479.82      |\n",
      "| 2023-12-01 |    465.74    |      477.98      |\n",
      "| 2023-12-04 |    453.9     |      474.93      |\n",
      "| 2023-12-05 |    455.15    |      467.66      |\n",
      "| 2023-12-06 |    446.73    |      461.97      |\n",
      "| 2023-12-07 |    452.0     |      458.08      |\n",
      "| 2023-12-08 |    453.76    |      454.88      |\n",
      "| 2023-12-11 |    459.89    |      453.83      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      456.99      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "TSLA\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    244.14    |      240.07      |\n",
      "| 2023-11-30 |    240.08    |      244.02      |\n",
      "| 2023-12-01 |    238.83    |      243.64      |\n",
      "| 2023-12-04 |    235.58    |      241.2       |\n",
      "| 2023-12-05 |    238.72    |      239.81      |\n",
      "| 2023-12-06 |    239.37    |      239.81      |\n",
      "| 2023-12-07 |    242.64    |      241.27      |\n",
      "| 2023-12-08 |    243.84    |      241.85      |\n",
      "| 2023-12-11 |    239.74    |      242.8       |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      242.66      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "NVDA\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    481.4     |      476.73      |\n",
      "| 2023-11-30 |    467.7     |      476.79      |\n",
      "| 2023-12-01 |    467.65    |      472.39      |\n",
      "| 2023-12-04 |    455.1     |      468.42      |\n",
      "| 2023-12-05 |    465.66    |      461.73      |\n",
      "| 2023-12-06 |    455.03    |      460.18      |\n",
      "| 2023-12-07 |    465.96    |      460.19      |\n",
      "| 2023-12-08 |    475.06    |      459.27      |\n",
      "| 2023-12-11 |    466.27    |      463.35      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |      464.02      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "GME\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-29 |    16.25     |      12.54       |\n",
      "| 2023-11-30 |    14.55     |      15.58       |\n",
      "| 2023-12-01 |     15.3     |       15.8       |\n",
      "| 2023-12-04 |    16.98     |      15.38       |\n",
      "| 2023-12-05 |    14.91     |      15.89       |\n",
      "| 2023-12-06 |    14.84     |      15.78       |\n",
      "| 2023-12-07 |    16.36     |      15.42       |\n",
      "| 2023-12-08 |    15.55     |      15.24       |\n",
      "| 2023-12-11 |    15.07     |      15.58       |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-12 |     TBA      |       15.4       |\n",
      "+------------+--------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Forecast next day\n",
    "\n",
    "stocks = ['GOOG', 'AAPL', 'MSFT', 'META', 'AMZN', 'NFLX', 'TSLA', 'NVDA', 'GME']\n",
    "\n",
    "for choosen_stock in stocks:\n",
    "    print(\"\\n\"+choosen_stock)\n",
    "    \n",
    "    # Function Call\n",
    "    file = open(\"Saved Params/\"+choosen_stock+\"_params.pkl\",'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    model = DynamicLSTM(object_file['input_size'], object_file['hidden_size'], object_file['num_layers'], object_file['output_size'])# .to(device)\n",
    "    model.load_state_dict(torch.load(\"Saved Models/\"+choosen_stock+\"_model\"))\n",
    "    model.eval()\n",
    "    \n",
    "    test_predict = model(object_file['test_X']).view(-1).cpu().detach().numpy()\n",
    "    test_data = object_file['test_data']\n",
    "    test_predict_inverse = object_file['test_predict_inverse']\n",
    "    test_Y_inverse = object_file['test_Y_inverse']\n",
    "    \n",
    "    formatted_dates = [test_dates.strftime('%Y-%m-%d') for test_dates in object_file[\"test_dates\"]]\n",
    "    formatted_test_Y = [\"{:.4f}\".format(price) for price in test_Y_inverse.flatten()]\n",
    "    formatted_test_predict = [\"{:.4f}\".format(price) for price in test_predict_inverse.flatten()]\n",
    "    \n",
    "    formatted_dates = formatted_dates[-14:-4]\n",
    "    formatted_test_predict = formatted_test_predict[-14:-4]\n",
    "    \n",
    "    # Display\n",
    "    # Remove the first value and shift up the remaining values\n",
    "    actual_prices = formatted_test_Y[0:] + ['']\n",
    "    actual_prices = actual_prices[-10:]\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Date\", \"Actual Price\", \"Predicted Price\"]\n",
    "    for date, actual_price, predicted_price in zip(formatted_dates, actual_prices, formatted_test_predict):\n",
    "        # Add a separator line before the last row\n",
    "        if date == formatted_dates[-1]:\n",
    "            table.add_row([\"-\" * 10, \"-\" * 12, \"-\" * 16])\n",
    "        table.add_row([date, round(float(actual_price), 2) if actual_price != '' else 'TBA', round(float(predicted_price), 2)])\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
